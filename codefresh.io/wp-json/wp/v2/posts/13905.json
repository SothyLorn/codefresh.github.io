{"id":13905,"date":"2019-06-07T08:02:57","date_gmt":"2019-06-07T08:02:57","guid":{"rendered":"http:\/\/codefresh.io\/?p=13905"},"modified":"2022-01-06T15:49:06","modified_gmt":"2022-01-06T15:49:06","slug":"docker-anti-patterns","status":"publish","type":"post","link":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/","title":{"rendered":"Docker anti-patterns"},"content":{"rendered":"<p>Container usage is exploding. Even if you are not yet convinced that Kubernetes is the way forward, it is very easy to add value just by using Docker on its own. Containers can now <a href=\"https:\/\/thenewstack.io\/docker-based-dynamic-tooling-a-frequently-overlooked-best-practice\/\">simplify both deployments and CI\/CD pipelines<\/a>.<\/p>\n<p>The official <a href=\"https:\/\/docs.docker.com\/develop\/develop-images\/dockerfile_best-practices\/\">Docker best practices page<\/a> is highly technical and focuses more on the structure of the Dockerfile instead of generic information on how to use containers in general. Every Docker newcomer will at some point understand the usage of Docker layers, how they are cached, and how to create small Docker images. Multi-stage builds are not rocket science either. The syntax of Dockerfiles is fairly easy to understand.<\/p>\n<p>However, the main problem of container usage is the inability of companies to look at the bigger picture and especially the immutable character of containers\/images. Several companies in particular attempt to convert their existing VM-based processes to containers with dubious results. There is a wealth of information on low-level details of containers (how to create them and run them), but very little information on high level best practices.<\/p>\n<p>To close this documentation gap, I present to you a list of high-level Docker best-practices. Since it is impossible to cover the internal processes of every company out there I will instead explain bad practices (i.e. what you should not do). Hopefully, this will give you some insights on how you should use containers.<\/p>\n<p>Here is the complete list of bad practices that we will examine:<\/p>\n<ol>\n<li>Attempting to use VM practices on containers.<\/li>\n<li>Creating Docker files that are not transparent.<\/li>\n<li>Creating Dockerfiles that have external side effects.<\/li>\n<li>Confusing images used for deployment with those used for development.<\/li>\n<li>Building different images per environment.<\/li>\n<li>Pulling code from git into production servers and building images on the fly.<\/li>\n<li>Promoting git hashes between teams.<\/li>\n<li>Hardcoding secrets into container images.<\/li>\n<li>Using Docker as poor man\u2019s CI\/CD.<\/li>\n<li>Assuming that containers are a dumb packaging method.<\/li>\n<\/ol>\n<h2>Anti-pattern 1 &#8211; Treating Docker containers as Virtual Machines<\/h2>\n<p>Before going into some more practical examples, let\u2019s get the basic theory out of the way first. Containers are not Virtual Machines. At first glance, they might look like they behave like VMs but the truth is completely different. Stackoverflow and related forums are filled with questions like:<\/p>\n<ol>\n<li><a href=\"https:\/\/unix.stackexchange.com\/questions\/123482\/application-updates-inside-of-docker-containers\">How to I update applications running inside containers?<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/28134239\/how-to-ssh-into-docker\">How do I ssh in a Docker container?<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/44744188\/how-to-see-the-logs-of-running-application-inside-docker-container\">How do I get logs\/files from a container?<\/a><\/li>\n<li><a href=\"https:\/\/serverfault.com\/questions\/611082\/how-to-handle-security-updates-within-docker-containers\">How do I apply security fixes inside a container?<\/a><\/li>\n<li><a href=\"https:\/\/stackoverflow.com\/questions\/19948149\/can-i-run-multiple-programs-in-a-docker-container\">How do I run multiple programs in a container?<\/a><\/li>\n<\/ol>\n<p>All these questions are technically correct, and the people that have answered them have also given technically correct answers. However, all these questions are the canonical example of <a href=\"https:\/\/en.wikipedia.org\/wiki\/XY_problem\">the XY problem<\/a>. The real question behind these questions is:<\/p>\n<blockquote><p>\u201cHow can I unlearn all my VM practices and processes and change my workflow to work with immutable, short-lived, stateless containers instead of mutable, long-running, stateful VMs?\u201d<\/p><\/blockquote>\n<p>Many companies out there are trying to reuse the same practices\/tools\/knowledge from VMs in the container world. Some companies were even caught completely off-guard as they had not even finished their bare-metal-to-vm migration when containers appeared.<\/p>\n<p>Unlearning something is very difficult. Most people that start using containers see them initially as an extra abstraction layer on top of their existing practices:<\/p>\n<figure id=\"attachment_13913\" aria-describedby=\"caption-attachment-13913\" style=\"width: 774px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/container-usage.png\"><img class=\"size-full wp-image-13913\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/container-usage.png\" alt=\"Containers are not VMs\" width=\"774\" height=\"441\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/container-usage.png 774w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/container-usage-300x171.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/container-usage-768x438.png 768w\" sizes=\"(max-width: 774px) 100vw, 774px\" \/><\/a><figcaption id=\"caption-attachment-13913\" class=\"wp-caption-text\">Containers are not VMs<\/figcaption><\/figure>\n<p>In reality, containers require a completely different view and change of existing processes. You need to rethink <strong>all <\/strong>your CI\/CD processes when adopting containers.<\/p>\n<figure id=\"attachment_13914\" aria-describedby=\"caption-attachment-13914\" style=\"width: 803px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/correct-container-usage.png\"><img class=\"size-full wp-image-13914\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/correct-container-usage.png\" alt=\"Containers require a new way of thinking\" width=\"803\" height=\"432\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/correct-container-usage.png 803w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/correct-container-usage-300x161.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/correct-container-usage-768x413.png 768w\" sizes=\"(max-width: 803px) 100vw, 803px\" \/><\/a><figcaption id=\"caption-attachment-13914\" class=\"wp-caption-text\">Containers require a new way of thinking<\/figcaption><\/figure>\n<p>There is no easy fix for this anti-pattern other than reading about the nature of containers, their building blocks, and their history (going all the way back to the venerable <a href=\"https:\/\/en.wikipedia.org\/wiki\/Chroot\">chroot<\/a>).<\/p>\n<p>If you regularly find yourself wanting to open ssh sessions to running containers in order to \u201cupgrade\u201d them or manually get logs\/files out of them you are definitely using Docker in the wrong way and you need to do some extra reading on how containers work.<\/p>\n<h2>Anti-pattern 2 &#8211; Creating Docker images that are not transparent<\/h2>\n<p>A Dockerfile should be transparent and self-contained. It should describe all the components of an application in plain sight. Anybody should be able to get the same Dockerfile and recreate the same image. It is ok if the Dockerfile downloads extra libraries (in a versioned and well-controlled manner) but creating Dockerfiles that perform \u201cmagic\u201d steps should be avoided.<\/p>\n<p>Here is a particularly bad example:<\/p>\n<pre>FROM alpine:3.4\n\nRUN apk add --no-cache \\\n      ca-certificates \\\n      pciutils \\\n      ruby \\\n      ruby-irb \\\n      ruby-rdoc \\\n      &amp;&amp; \\\n    echo http:\/\/dl-4.alpinelinux.org\/alpine\/edge\/community\/ &gt;&gt; \/etc\/apk\/repositories &amp;&amp; \\\n    apk add --no-cache shadow &amp;&amp; \\\n    gem install puppet:\"5.5.1\" facter:\"2.5.1\" &amp;&amp; \\\n    \/usr\/bin\/puppet module install puppetlabs-apk\n\n# Install Java application\nRUN \/usr\/bin\/puppet agent --onetime --no-daemonize\n\nENTRYPOINT [\"java\",\"-jar\",\"\/app\/spring-boot-application.jar\"]\n<\/pre>\n<p>Now don\u2019t get me wrong. I love Puppet as it is a great tool (or Ansible, or Chef for that matter). Misusing it for application deployments might have been easy with VMs, but with containers it is disastrous.<\/p>\n<p>First of all, it makes this Dockerfile location-dependent. You have to build it on a computer that has access to the production Puppet server. Does your workstation have access to the production puppet server? If yes, should your workstation really have access to the production puppet server?<\/p>\n<p>But the biggest problem is that this Docker image cannot be easily recreated. Its contents depend on what the puppet server had at the time of the initial build. If you build the same Dockerfile today you might get a completely different image. And if you don\u2019t have access to the puppet server or the puppet server is down you cannot even build the image in the first place. You don\u2019t even know what is the version of the application if you don\u2019t have access to the puppet scripts.<\/p>\n<p>The team that created this Dockerfile was just lazy. There was already a puppet script for installing the application in a VM. The Dockerfile was just retrofitted to do the same thing (see the previous anti-pattern).<\/p>\n<p>The fix here is to have minimal Dockerfiles that describe explicitly what they do. Here is the same application with the \u201cproper\u201d Dockerfile.<\/p>\n<pre>FROM openjdk:8-jdk-alpine\n\nENV MY_APP_VERSION=\"3.2\"\n\nRUN apk add --no-cache \\\n      ca-certificates\n\nWORKDIR \/app\nADD  http:\/\/artifactory.mycompany.com\/releases\/${MY_APP_VERSION}\/spring-boot-application.jar .\n\nENTRYPOINT [\"java\",\"-jar\",\"\/app\/spring-boot-application.jar\"]\n<\/pre>\n<p>Notice that:<\/p>\n<ol>\n<li>There is no dependency on puppet infrastructure. The Dockerfile can be built on any developer machine that has access to the binary repository<\/li>\n<li>Versions of the software are explicitly defined.<\/li>\n<li>It is very easy to change the version of the application by editing only the Dockerfile (instead of puppet scripts).<\/li>\n<\/ol>\n<p>This was just a very simple (and contrived) example. I have seen many Dockerfiles in the wild that depend on \u201cmagic\u201d recipes with special requirements for the time and place they can be built. Please don\u2019t write your Dockerfiles in this manner, as developers (and other people who don\u2019t have access to all systems) will have great difficulties creating Docker images locally.<\/p>\n<p>An even better alternative would be if the Dockerfile compiled the source Java code on its own (using multi-stage builds). That would give you even greater visibility on what is happening in the Docker image.<\/p>\n<h2>Anti-pattern 3 -Creating Dockerfiles that have external side effects<\/h2>\n<p>Let&#8217;s imagine that you are an operator\/SRE working at very big company where multiple programming languages are used. It would be very difficult to become an expert in all the programming languages and build systems out there.<\/p>\n<p>This is one of the major advantages of adopting containers in the first place. You should be able to download any Dockerfile from any development team and build it without really caring about side effects (because there shouldn\u2019t be any).<\/p>\n<p>Building a Docker image should be an idempotent operation. It shouldn\u2019t matter if you build the same Dockerfile one time or a thousand times. Or if you build it on a CI server first and then on your workstation.<\/p>\n<p>Yet, there are several Dockerfiles out there that during the build phase&#8230;<\/p>\n<ol>\n<li>perform git commits or other git actions,<\/li>\n<li>clean up or tamper with database data,<\/li>\n<li>or call other external services with POST\/PUT operations.<\/li>\n<\/ol>\n<p>Containers offer isolation as far as the host filesystem is concerned but there is nothing protecting you from a Dockerfile that contains a RUN directive with curl POSTING an HTTP payload to your intranet.<\/p>\n<p>Here is a simple example where a Dockerfile both packages (a safe action) and publishes (an unsafe action) an npm application in a single run.<\/p>\n<pre>FROM node:9\nWORKDIR \/app\n\nCOPY package.json .\/package.json\nCOPY package-lock.json .\/package-lock.json\nRUN npm install\nCOPY . .\n\nRUN npm test\n\nARG npm_token\n\nRUN echo \"\/\/registry.npmjs.org\/:_authToken=${npm_token}\" &gt; .npmrc\nRUN npm publish --access public\n\nEXPOSE 8080\nCMD [ \"npm\", \"start\" ]\n<\/pre>\n<p>This Docker file confuses two unrelated concerns, releasing a version of the application, and creating a Docker image for it. Maybe sometimes these two actions happen indeed together at the same time, but this is no excuse for polluting a Dockerfile with side effects.<\/p>\n<p>Docker is <strong>NOT <\/strong>a generic CI system and it was never meant to be one. Don\u2019t abuse Dockerfiles as glorified bash scripts that have unlimited power. Having side effects while containers are running is ok. Having side effects during container build time is not.<\/p>\n<p>The solution is to simplify your Dockerfiles and make sure that they only contain idempotent operations such as:<\/p>\n<ul>\n<li>Cloning source code<\/li>\n<li>Downloading dependencies<\/li>\n<li>Compiling\/packaging code<\/li>\n<li>Processing\/Minifying\/Transforming local resources<\/li>\n<li>Running scripts and editing files on the container filesystem only<\/li>\n<\/ul>\n<p>Also, keep in mind the ways Docker caches filesystem layers. Docker assumes that if a layer and the ones before it have not \u201cchanged\u201d they can be reused from cache. If your Dockerfile directives have side effects you essentially break the Docker caching mechanism.<\/p>\n<pre>FROM node:10.15-jessie\n\nRUN apt-get update &amp;&amp; apt-get install -y mysql-client &amp;&amp; rm -rf \/var\/lib\/apt\n\nRUN mysql -u root --password=\"\" &lt; test\/prepare-db-for-tests.sql\n\nWORKDIR \/app\n\nCOPY package.json .\/package.json\nCOPY package-lock.json .\/package-lock.json\nRUN npm install\nCOPY . .\n\nRUN npm integration-test\n\nEXPOSE 8080\nCMD [ \"npm\", \"start\" ]\n<\/pre>\n<p>Let\u2019s say that you try to build this Dockerfile and your unit tests fail. You make a change to the source code and you try to rebuild again. Docker will assume that the layer that clears the DB is already \u201crun\u201d and it will reuse the cache. So your unit tests will now run in a DB that isn\u2019t cleaned and contains data from the previous run.<\/p>\n<p>In this contrived example, the Dockerfile is very small and it is very easy to locate the statement that has side effects (the mysql command) and move it to the correct place in order to fix layer caching. But in a real Dockerfile with many commands, trying to hunt down the correct order of RUN statements is very difficult if you don\u2019t know which have side effects and which do not.<\/p>\n<p>Your Dockerfiles will be much simpler if all actions they perform are read-only and with local scope.<\/p>\n<h2>Anti-pattern 4 -Confusing images that are used for development with those that are used for deployment<\/h2>\n<p>In any company that has adopted containers, there are usually two separate categories of Docker images. First, there are the images that are used as the actual deployment artifact sent to production servers.<\/p>\n<p>The deployment images should contain:<\/p>\n<ol>\n<li>The application code in minified\/compiled form plus its runtime dependencies.<\/li>\n<li>Nothing else. Really nothing else.<\/li>\n<\/ol>\n<p>The second category is the images used for the CI\/CD systems or developers and might contain:<\/p>\n<ol>\n<li>The source code in its original form (i.e. unminified)<\/li>\n<li>Compilers\/minifiers\/transpilers<\/li>\n<li>Testing frameworks\/reporting tools<\/li>\n<li>Security scanning, quality scanning, static analyzers<\/li>\n<li>Cloud integration tools<\/li>\n<li>Other utilities needed for the CI\/CD pipeline<\/li>\n<\/ol>\n<p>It should be obvious that these categories of container images should be handled separately as they have different purposes and goals. Images that get deployed to servers should be minimal, secure and battle-hardened. Images that get used in the <a href=\"https:\/\/thenewstack.io\/understanding-the-difference-between-ci-and-cd\/\">CI\/CD <\/a>process are never actually deployed anywhere so they have much less strict requirements (for size and security).<\/p>\n<p>Yet for some reason, people do not always understand this distinction. I have seen several companies who try to use the same Docker image both for development and for deployment. Almost always what happens is that unrelated utilities and frameworks end up in the production Docker image.<\/p>\n<p>There are exactly 0 reasons on why a production Docker image should contain git, test frameworks, or compilers\/minifiers.<\/p>\n<p>The promise of containers as a universal deployment artifact was always about using the same deployment artifact between different environments and making sure that what you are testing is also what you are deploying (more on this later). But trying to consolidate local development with production deployments is a losing battle.<\/p>\n<p>In summary, try to understand the roles of your Docker images. Each image should have a single role. If you are shipping test frameworks\/libraries to production you are doing it wrong. You should also spend some time to learn and use <a href=\"https:\/\/docs.docker.com\/develop\/develop-images\/multistage-build\/\">multi-stage builds<\/a>.<\/p>\n<h2>Anti-pattern 5 -Using different images for each environment (qa, stage, production)<\/h2>\n<p>One of the most important advantages of using containers is their immutable attribute. This means that a Docker image should be built only once and then promoted to various environments until it reaches production.<\/p>\n<figure id=\"attachment_13929\" aria-describedby=\"caption-attachment-13929\" style=\"width: 851px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-promotion-1.png\"><img class=\"wp-image-13929 size-full\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-promotion-1.png\" alt=\"Promoting the same Docker image\" width=\"851\" height=\"365\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-promotion-1.png 851w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-promotion-1-300x129.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-promotion-1-768x329.png 768w\" sizes=\"(max-width: 851px) 100vw, 851px\" \/><\/a><figcaption id=\"caption-attachment-13929\" class=\"wp-caption-text\">Promoting the same Docker image<\/figcaption><\/figure>\n<p>Because the exact same image is promoted as a single entity, you get the guarantee that what you are testing in one environment is the same as the other.<\/p>\n<p>I see a lot of companies that build different artifacts for their environments with slightly different versions of code or configuration.<\/p>\n<figure id=\"attachment_13927\" aria-describedby=\"caption-attachment-13927\" style=\"width: 636px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-per-env-1.png\"><img class=\"wp-image-13927 size-full\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-per-env-1.png\" alt=\"Different image per environment\" width=\"636\" height=\"528\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-per-env-1.png 636w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/image-per-env-1-300x249.png 300w\" sizes=\"(max-width: 636px) 100vw, 636px\" \/><\/a><figcaption id=\"caption-attachment-13927\" class=\"wp-caption-text\">Different image per environment<\/figcaption><\/figure>\n<p>This is problematic because there is no guarantee that images are \u201csimilar enough\u201d to verify that they behave in the same manner. It also opens a lot of possibilities for abuse, where developers\/operators are sneaking in extra debugging tools in the non-production images creating an even bigger rift between images for different environments.<\/p>\n<p>Instead of trying to make sure that your different images are the same as possible, it is far easier to use a single image for all software lifecycle phases.<\/p>\n<p>Note that it is perfectly normal if the different environments use different settings (i.e. secrets and configuration variables) as we will see later in this article. Everything else, however, should be exactly the same.<\/p>\n<h2>Anti-pattern 6 -Creating Docker images on production servers<\/h2>\n<p>The Docker registry serves as a catalog of existing applications that can be re-deployed at any time to any additional environments. It is also a central location of application assets with extra metadata along with previous historical versions of the same application. It should be very easy to choose a specific tag of a Docker image and deploy it to any environment.<\/p>\n<p>One of the most flexible ways of using Docker registries is by promoting images between them. An organization has at least two registries (the development one and the production one). A Docker image should be built once (see previous anti-pattern) and placed in the development registry. Then, once integration tests, security scans, and other quality gates verify its correct functionality, the image can be promoted to the production Docker registry to be sent to production servers or Kubernetes clusters.<\/p>\n<p>Is also possible to have different organizations for Docker registries per region\/location or per department. The main point here is that the canonical way for Docker deployments also includes a Docker registry. Docker registries serve both as an application asset repository as well as intermediate storage before an application is deployed to production.<\/p>\n<p>A very questionable practice is the complete removal of Docker registries from the lifecycle and the pushing of source code directly to production servers.<\/p>\n<figure id=\"attachment_13919\" aria-describedby=\"caption-attachment-13919\" style=\"width: 886px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/pulle-code.png\"><img class=\"size-full wp-image-13919\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/pulle-code.png\" alt=\"Building images in production servers\" width=\"886\" height=\"572\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/pulle-code.png 886w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/pulle-code-300x194.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/pulle-code-768x496.png 768w\" sizes=\"(max-width: 886px) 100vw, 886px\" \/><\/a><figcaption id=\"caption-attachment-13919\" class=\"wp-caption-text\">Building images in production servers<\/figcaption><\/figure>\n<p>Production servers use \u201cgit pull\u201d to get the source code and then Docker build to create an image on the fly and run it locally (usually with Docker-compose or other custom orchestration). This \u201cdeployment method\u201d essentially employs multiple anti-patterns all at once!<\/p>\n<p>This deployment practice suffers from a lot of issues, starting with security. Production servers should not have inbound access to your git repositories. If a company is serious about security, this pattern will not even fly with the security committee. There is also no reason why production servers should have git installed. Git (or any other version control system) is a tool intended for developer collaboration and not an artifact delivery solution.<\/p>\n<p>But the most critical issue is that with this \u201cdeployment method\u201d you bypass completely the scope of Docker registries. You no longer know what Docker image is deployed on your servers as there is no central place that holds Docker images anymore.<\/p>\n<p>This deployment method might work ok in a startup, but will quickly become inefficient in bigger installations. You need to learn how to use Docker registries and the advantages they bring (also related to security scanning of containers).<\/p>\n<figure id=\"attachment_13920\" aria-describedby=\"caption-attachment-13920\" style=\"width: 875px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/use-docker-registry.png\"><img class=\"size-full wp-image-13920\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/use-docker-registry.png\" alt=\"Using a Docker registry\" width=\"875\" height=\"602\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/use-docker-registry.png 875w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/use-docker-registry-300x206.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/use-docker-registry-768x528.png 768w\" sizes=\"(max-width: 875px) 100vw, 875px\" \/><\/a><figcaption id=\"caption-attachment-13920\" class=\"wp-caption-text\">Using a Docker registry<\/figcaption><\/figure>\n<p>Docker registries have a well-defined API, and there are several open-source and proprietary products that can be used to set-up one within your organization.<\/p>\n<p>Notice also that with Docker registries your source code securely resides behind the firewall and never leaves the premises.<\/p>\n<h2>Anti-pattern 7 -Working with git hashes instead of Docker images<\/h2>\n<p>A corollary to the previous two anti-patterns is that once you adopt containers, your Docker registry should become the single point of truth for everything. People should talk in terms of Docker tags and image promotions. Developers and operators should use containers as their common language. The hand-over entity between teams should be a container and not a git hash.<\/p>\n<figure id=\"attachment_13921\" aria-describedby=\"caption-attachment-13921\" style=\"width: 832px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/git-handoff.png\"><img class=\"size-full wp-image-13921\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/git-handoff.png\" alt=\"Talking about git hashes\" width=\"832\" height=\"353\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/git-handoff.png 832w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/git-handoff-300x127.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/git-handoff-768x326.png 768w\" sizes=\"(max-width: 832px) 100vw, 832px\" \/><\/a><figcaption id=\"caption-attachment-13921\" class=\"wp-caption-text\">Talking about git hashes<\/figcaption><\/figure>\n<p>This comes in contrast with the old way of using Git hashes as \u201cpromotion\u201d artifacts. The source code is of course important, but re-building the same hash over and over in order to promote it is a waste of resources (see also anti-pattern 5). Several companies think that containers should only be handled by operators, while developers are still working with just the source code. This could not be further from the truth. Containers are the perfect opportunity for developers and operators to work together.<\/p>\n<figure id=\"attachment_13922\" aria-describedby=\"caption-attachment-13922\" style=\"width: 831px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/docker-handoff.png\"><img class=\"size-full wp-image-13922\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/docker-handoff.png\" alt=\"Talking about containers\" width=\"831\" height=\"381\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/docker-handoff.png 831w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/docker-handoff-300x138.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/docker-handoff-768x352.png 768w\" sizes=\"(max-width: 831px) 100vw, 831px\" \/><\/a><figcaption id=\"caption-attachment-13922\" class=\"wp-caption-text\">Talking about containers<\/figcaption><\/figure>\n<p>Ideally, operators should not even care about what goes on with the git repo of an application. All they need to know is if the Docker image they have at hand is ready to be pushed to production or not. They should not be forced to rebuild a git hash in order to get the same Docker image that developers were using in pre-production environments.<\/p>\n<p>You can understand if you are the victim of this anti-pattern by asking operators in your organization. If they are forced to become familiar with application internals such as build systems or test frameworks that normally are not related to the actual runtime of the application, they have a heavy cognitive load which is otherwise not needed for daily operations.<\/p>\n<h2>Anti-pattern 8 -Hardcoding secrets and configuration into container images<\/h2>\n<p>This anti-pattern is closely related to Anti-pattern 5 (different images per environment). In most cases when I ask companies why they need different images for qa\/staging\/production, the usual answer is that they contain different configurations and secrets.<\/p>\n<p>This not only breaks the main promise of Docker (deploy what you tested) but also makes all CI\/CD pipelines very complex as they have to manage secrets\/configuration during build time.<\/p>\n<p>The anti-pattern here is, of course, the hard-coding of configurations. Applications should not have embedded configurations. This should not be news for anybody who is familiar <a href=\"https:\/\/12factor.net\/config\">with 12-factor apps<\/a>.<\/p>\n<figure id=\"attachment_13923\" aria-describedby=\"caption-attachment-13923\" style=\"width: 713px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/hardcode-conf.png\"><img class=\"size-full wp-image-13923\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/hardcode-conf.png\" alt=\"Hardcoding configuration at build time\" width=\"713\" height=\"309\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/hardcode-conf.png 713w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/hardcode-conf-300x130.png 300w\" sizes=\"(max-width: 713px) 100vw, 713px\" \/><\/a><figcaption id=\"caption-attachment-13923\" class=\"wp-caption-text\">Hardcoding configuration at build time<\/figcaption><\/figure>\n<p>Your applications should fetch configuration during runtime instead of build time. A Docker image should be configuration agnostic. Only during runtime configuration should be \u201cattached\u201d to the container. There are many solutions for this and most clustering\/deployment systems can work with a solution for runtime configuration (<a href=\"https:\/\/kubernetes.io\/docs\/tasks\/configure-pod-container\/configure-pod-configmap\/\">configmaps<\/a>, <a href=\"http:\/\/zookeeper.apache.org\/\">zookeeper<\/a>, <a href=\"https:\/\/www.consul.io\/\">consul <\/a>etc) and secrets (<a href=\"https:\/\/www.vaultproject.io\/\">vault<\/a>, <a href=\"https:\/\/square.github.io\/keywhiz\/\">keywhiz<\/a>, <a href=\"https:\/\/lyft.github.io\/confidant\/\">confidant<\/a>, <a href=\"http:\/\/engineering.nike.com\/cerberus\/\">cerberus<\/a>).<\/p>\n<figure id=\"attachment_13924\" aria-describedby=\"caption-attachment-13924\" style=\"width: 840px\" class=\"wp-caption alignnone\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/runtime-conf.png\"><img class=\"size-full wp-image-13924\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/runtime-conf.png\" alt=\"Loading configuration during runtime\" width=\"840\" height=\"394\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/runtime-conf.png 840w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/runtime-conf-300x141.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/runtime-conf-768x360.png 768w\" sizes=\"(max-width: 840px) 100vw, 840px\" \/><\/a><figcaption id=\"caption-attachment-13924\" class=\"wp-caption-text\">Loading configuration during runtime<\/figcaption><\/figure>\n<p>If your Docker image has hardcoded IPs and\/or credentials you are definitely doing it wrong.<\/p>\n<h2>Anti-pattern 9 -Creating Docker files that do too much<\/h2>\n<p>I have come across articles who suggest that Dockerfiles should be used as a poor man\u2019s CI solution. Here is an actual example of a single Dockerfile.<\/p>\n<pre># Run Sonar analysis\nFROM newtmitch\/sonar-scanner AS sonar\nCOPY src src\nRUN sonar-scanner\n# Build application\nFROM node:11 AS build\nWORKDIR \/usr\/src\/app\nCOPY . .\nRUN yarn install \\\n yarn run lint \\\n yarn run build \\\n yarn run generate-docs\nLABEL stage=build\n# Run unit test\nFROM build AS unit-tests\nRUN yarn run unit-tests\nLABEL stage=unit-tests\n# Push docs to S3\nFROM containerlabs\/aws-sdk AS push-docs\nARG push-docs=false\nCOPY --from=build docs docs\nRUN [[ \"$push-docs\" == true ]] &amp;&amp; aws s3 cp -r docs s3:\/\/my-docs-bucket\/\n# Build final app\nFROM node:11-slim\nEXPOSE 8080\nWORKDIR \/usr\/src\/app\nCOPY --from=build \/usr\/src\/app\/node_modules node_modules\nCOPY --from=build \/usr\/src\/app\/dist dist\nUSER node\nCMD [\"node\", \".\/dist\/server\/index.js\"]\n<\/pre>\n<p>While at first glance this Docker file might look like a good use of multi-stage builds, it is essentially a combination of previous anti-patterns.<\/p>\n<ul>\n<li>It assumes the presence of a SonarQube server (anti-pattern 2).<\/li>\n<li>It has potential side effects as it can push to S3 (anti-pattern 3).<\/li>\n<li>It acts both as a development as well as a deployment image (anti-pattern 4).<\/li>\n<\/ul>\n<p>Docker is not a CI system on its own. Container technology can be used as part of a CI\/CD pipeline, but this technique is something completely different. Don\u2019t confuse commands that need to run in the Docker container with commands that need to run in a CI build job.<\/p>\n<p>The <a href=\"https:\/\/itnext.io\/shift-your-ci-scripts-to-docker-build-92453bca9f75\">author of this Dockerfile advocates<\/a> that you should use build arguments that interact with the labels and switch on\/off specific build phases (so you could disable sonar for example). But this approach is just adding complexity for the sake of complexity.<\/p>\n<p>The way to fix this Dockerfile is to split it into 5 other Dockerfiles. One is used for the application deployment and all others are different pipeline steps in your CI\/CD pipeline. A single Dockerfile should have a single purpose\/goal.<\/p>\n<h2>Anti-pattern 10 -Creating Docker files that do too little<\/h2>\n<p>Because containers also include their dependencies, they are great for isolating library and framework versions per application. Developers are already familiar with the issues of trying to install multiple versions of the same tool on their workstation. Docker promises to solve this problem by allowing you to describe in your Dockerfile exactly what your application needs and nothing more.<\/p>\n<p>But this Docker promise only holds true if you actually employ it. As an operator, I should not really care about the programming tool you use in your Docker image. I should be able to create a Docker image of a Java application, then a Python one and then a NodeJs one, without actually having a development environment for each language on my laptop.<\/p>\n<p>A lot of companies however still see Docker as a dumb package format and just use it to package a finished artifact\/application that was already created outside of the container. This anti-pattern is very famous with Java heavy organizations and even official documentation seems to promote it.<\/p>\n<p>Here is the suggested Dockerfile from the <a href=\"https:\/\/spring.io\/guides\/gs\/spring-boot-docker\/\">official Spring Boot Docker guide<\/a>.<\/p>\n<pre>FROM openjdk:8-jdk-alpine\nVOLUME \/tmp\nARG JAR_FILE\nCOPY ${JAR_FILE} app.jar\nENTRYPOINT [\"java\",\"-Djava.security.egd=file:\/dev\/.\/urandom\",\"-jar\",\"\/app.jar\"]\n<\/pre>\n<p>This Dockerfile just packages an existing jar file. How was the Jar file created? Nobody knows. It is not described in the Dockerfile. If I am an operator I am forced to install all Java development libraries locally just to build this Dockerfile. And if you work in an organization that works with multiple programming languages this process gets quickly out of hand not only for operators but also for build nodes.<\/p>\n<p>I am using Java as an example here but this anti-pattern is present in other situations as well. Dockerfiles that don\u2019t work unless you have first performed an \u201cnpm install\u201d locally first are a very common occurrence.<\/p>\n<p>The solution to this anti-pattern is the same for anti-pattern 2 (Dockerfiles that are not self-contained). Make sure that your Dockerfiles describe the whole process of something. Your operators\/SREs will love you even more if you follow this approach. In the case of the Java example before the Dockerfile should be modified as below:<\/p>\n<pre>FROM openjdk:8-jdk-alpine\nCOPY pom.xml \/tmp\/\nCOPY src \/tmp\/src\/\nWORKDIR \/tmp\/\nRUN .\/gradlew build\nCOPY  \/tmp\/build\/app.war \/app.jar\nENTRYPOINT [\"java\",\"-Djava.security.egd=file:\/dev\/.\/urandom\",\"-jar\",\"\/app.jar\"]\n<\/pre>\n<p>This Dockerfile described exactly how the application is created and can be run by anybody on any workstation without the need for local Java installation. You can improve this Dockerfile even further with multi-stage builds (exercise for the reader).<\/p>\n<h2>Summary<\/h2>\n<p>A lot of companies have trouble adopting containers because they attempt to shoehorn their existing VM practices into containers. It is best to spend some time to rethink all the advantages that containers have and understand how you can create your process from scratch with that new knowledge.<\/p>\n<p>In this guide, I have presented several bad practices with container usage and also the solution to each one.<\/p>\n<ol>\n<li>Attempting to use VM practices on containers. Solution: understand what containers are.<\/li>\n<li>Creating Docker files that are not transparent. Solution: write Dockerfiles from scratch instead of adopting existing scripts.<\/li>\n<li>Creating Dockerfiles that have external side effects. Solution: move side effects to your CI\/CD solution and keep Dockerfiles side-effect free.<\/li>\n<li>Confusing images used for deployment with those used for development. Solution: don\u2019t ship development tools and test frameworks into production servers.<\/li>\n<li>Building different images per environment. Solution: build an image only once and promote it across various environments<\/li>\n<li>Pulling code from git intro production servers and building images on the fly. Solution: use a Docker registry<\/li>\n<li>Promoting git hashes between teams. Solution: promote container images between teams<\/li>\n<li>Hardcoding secrets into container images. Solution: build an image only once and use runtime configuration injection<\/li>\n<li>Using Docker as CI\/CD. Solution: use Docker as a deployment artifact and choose a CI\/CD solution for CI\/CD<\/li>\n<li>Assuming that containers are a dumb packaging method. Solution: Create Dockerfiles that compile\/package source code on their own from scratch.<\/li>\n<\/ol>\n<p>Look at your workflows, ask developers (if you are an operator) or operators (if you are a developer) and try to find if your company falls into one or more of these bad practices.<\/p>\n<p>Do you know of any other good\/bad container practices? Let us know in the comments below.<\/p>\n<input class=\"fooboxshare_post_id\" type=\"hidden\" value=\"13905\"\/>","protected":false},"excerpt":{"rendered":"<p>Container usage is exploding. Even if you are not yet convinced that Kubernetes is the way forward, it is very easy to add value just by using Docker on its own. Containers can now simplify both deployments and CI\/CD pipelines. The official Docker best practices page is highly technical and focuses more on the structure &hellip; <a href=\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/\">Read more<\/a><\/p>\n","protected":false},"author":62,"featured_media":13819,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[3120,8,1505,1543,1538],"tags":[14,15,22,24,52,53,54,68],"yoast_head":"<!-- This site is optimized with the Yoast SEO Premium plugin v17.9 (Yoast SEO v18.4.1) - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>Docker Anti Patterns<\/title>\n<meta name=\"description\" content=\"In this article, we&#039;ll present several bad practices with container usage and the solution to each one.\" \/>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"Docker anti-patterns\" \/>\n<meta property=\"og:description\" content=\"In this article, we&#039;ll present several bad practices with container usage and the solution to each one.\" \/>\n<meta property=\"og:url\" content=\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/\" \/>\n<meta property=\"og:site_name\" content=\"Codefresh\" \/>\n<meta property=\"article:publisher\" content=\"https:\/\/www.facebook.com\/codefresh.io\" \/>\n<meta property=\"article:published_time\" content=\"2019-06-07T08:02:57+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2022-01-06T15:49:06+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg\" \/>\n\t<meta property=\"og:image:width\" content=\"670\" \/>\n\t<meta property=\"og:image:height\" content=\"200\" \/>\n\t<meta property=\"og:image:type\" content=\"image\/jpeg\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:creator\" content=\"@codefresh\" \/>\n<meta name=\"twitter:site\" content=\"@codefresh\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"Kostis Kapelonis\" \/>\n\t<meta name=\"twitter:label2\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"23 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"Organization\",\"@id\":\"https:\/\/codefresh.io\/#organization\",\"name\":\"Codefresh\",\"url\":\"https:\/\/codefresh.io\/\",\"sameAs\":[\"https:\/\/www.facebook.com\/codefresh.io\",\"https:\/\/www.linkedin.com\/company\/codefresh\",\"https:\/\/www.youtube.com\/channel\/UC9r94SY6BqN05kXPIHsDXPg\",\"https:\/\/twitter.com\/codefresh\"],\"logo\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/codefresh.io\/#logo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png\",\"contentUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png\",\"width\":800,\"height\":800,\"caption\":\"Codefresh\"},\"image\":{\"@id\":\"https:\/\/codefresh.io\/#logo\"}},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/codefresh.io\/#website\",\"url\":\"https:\/\/codefresh.io\/\",\"name\":\"Codefresh\",\"description\":\"\",\"publisher\":{\"@id\":\"https:\/\/codefresh.io\/#organization\"},\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/codefresh.io\/?s={search_term_string}\"},\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"en-US\"},{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#primaryimage\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg\",\"contentUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg\",\"width\":670,\"height\":200},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#webpage\",\"url\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/\",\"name\":\"Docker Anti Patterns\",\"isPartOf\":{\"@id\":\"https:\/\/codefresh.io\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#primaryimage\"},\"datePublished\":\"2019-06-07T08:02:57+00:00\",\"dateModified\":\"2022-01-06T15:49:06+00:00\",\"description\":\"In this article, we'll present several bad practices with container usage and the solution to each one.\",\"breadcrumb\":{\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/\"]}]},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/codefresh.io\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"Docker anti-patterns\"}]},{\"@type\":\"Article\",\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#article\",\"isPartOf\":{\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#webpage\"},\"author\":{\"@id\":\"https:\/\/codefresh.io\/#\/schema\/person\/b2f763eca5adecaee359ad3170055d87\"},\"headline\":\"Docker anti-patterns\",\"datePublished\":\"2019-06-07T08:02:57+00:00\",\"dateModified\":\"2022-01-06T15:49:06+00:00\",\"mainEntityOfPage\":{\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#webpage\"},\"wordCount\":4172,\"commentCount\":37,\"publisher\":{\"@id\":\"https:\/\/codefresh.io\/#organization\"},\"image\":{\"@id\":\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#primaryimage\"},\"thumbnailUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg\",\"keywords\":[\"docker\",\"continuous integration\",\"monitoring\",\"Containers\",\"devops\",\"CI\/CD\",\"build\",\"continuous delivery\"],\"articleSection\":[\"Continuous Deployment\/Delivery\",\"Docker Tutorials\",\"Containers\",\"Continuous Integration\",\"DevOps Tutorials\"],\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"CommentAction\",\"name\":\"Comment\",\"target\":[\"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#respond\"]}]},{\"@type\":\"Person\",\"@id\":\"https:\/\/codefresh.io\/#\/schema\/person\/b2f763eca5adecaee359ad3170055d87\",\"name\":\"Kostis Kapelonis\",\"image\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/codefresh.io\/#personlogo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/03\/branded-96x96.png\",\"contentUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/03\/branded-96x96.png\",\"caption\":\"Kostis Kapelonis\"},\"description\":\"Kostis is a software engineer\/technical-writer dual class character. He lives and breathes automation, good testing practices and stress-free deployments with GitOps.\",\"url\":\"https:\/\/codefresh.io\/author\/kostiscodefresh-io\/\"}]}<\/script>\n<!-- \/ Yoast SEO Premium plugin. -->","yoast_head_json":{"title":"Docker Anti Patterns","description":"In this article, we'll present several bad practices with container usage and the solution to each one.","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/","og_locale":"en_US","og_type":"article","og_title":"Docker anti-patterns","og_description":"In this article, we'll present several bad practices with container usage and the solution to each one.","og_url":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/","og_site_name":"Codefresh","article_publisher":"https:\/\/www.facebook.com\/codefresh.io","article_published_time":"2019-06-07T08:02:57+00:00","article_modified_time":"2022-01-06T15:49:06+00:00","og_image":[{"width":670,"height":200,"url":"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg","type":"image\/jpeg"}],"twitter_card":"summary_large_image","twitter_creator":"@codefresh","twitter_site":"@codefresh","twitter_misc":{"Written by":"Kostis Kapelonis","Est. reading time":"23 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"Organization","@id":"https:\/\/codefresh.io\/#organization","name":"Codefresh","url":"https:\/\/codefresh.io\/","sameAs":["https:\/\/www.facebook.com\/codefresh.io","https:\/\/www.linkedin.com\/company\/codefresh","https:\/\/www.youtube.com\/channel\/UC9r94SY6BqN05kXPIHsDXPg","https:\/\/twitter.com\/codefresh"],"logo":{"@type":"ImageObject","@id":"https:\/\/codefresh.io\/#logo","inLanguage":"en-US","url":"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png","contentUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png","width":800,"height":800,"caption":"Codefresh"},"image":{"@id":"https:\/\/codefresh.io\/#logo"}},{"@type":"WebSite","@id":"https:\/\/codefresh.io\/#website","url":"https:\/\/codefresh.io\/","name":"Codefresh","description":"","publisher":{"@id":"https:\/\/codefresh.io\/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/codefresh.io\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"ImageObject","@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#primaryimage","inLanguage":"en-US","url":"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg","contentUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg","width":670,"height":200},{"@type":"WebPage","@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#webpage","url":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/","name":"Docker Anti Patterns","isPartOf":{"@id":"https:\/\/codefresh.io\/#website"},"primaryImageOfPage":{"@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#primaryimage"},"datePublished":"2019-06-07T08:02:57+00:00","dateModified":"2022-01-06T15:49:06+00:00","description":"In this article, we'll present several bad practices with container usage and the solution to each one.","breadcrumb":{"@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/codefresh.io\/containers\/docker-anti-patterns\/"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/codefresh.io\/"},{"@type":"ListItem","position":2,"name":"Docker anti-patterns"}]},{"@type":"Article","@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#article","isPartOf":{"@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#webpage"},"author":{"@id":"https:\/\/codefresh.io\/#\/schema\/person\/b2f763eca5adecaee359ad3170055d87"},"headline":"Docker anti-patterns","datePublished":"2019-06-07T08:02:57+00:00","dateModified":"2022-01-06T15:49:06+00:00","mainEntityOfPage":{"@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#webpage"},"wordCount":4172,"commentCount":37,"publisher":{"@id":"https:\/\/codefresh.io\/#organization"},"image":{"@id":"https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#primaryimage"},"thumbnailUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2019\/06\/Docker_Anti-patterns_670x200.jpg","keywords":["docker","continuous integration","monitoring","Containers","devops","CI\/CD","build","continuous delivery"],"articleSection":["Continuous Deployment\/Delivery","Docker Tutorials","Containers","Continuous Integration","DevOps Tutorials"],"inLanguage":"en-US","potentialAction":[{"@type":"CommentAction","name":"Comment","target":["https:\/\/codefresh.io\/containers\/docker-anti-patterns\/#respond"]}]},{"@type":"Person","@id":"https:\/\/codefresh.io\/#\/schema\/person\/b2f763eca5adecaee359ad3170055d87","name":"Kostis Kapelonis","image":{"@type":"ImageObject","@id":"https:\/\/codefresh.io\/#personlogo","inLanguage":"en-US","url":"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/03\/branded-96x96.png","contentUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/03\/branded-96x96.png","caption":"Kostis Kapelonis"},"description":"Kostis is a software engineer\/technical-writer dual class character. He lives and breathes automation, good testing practices and stress-free deployments with GitOps.","url":"https:\/\/codefresh.io\/author\/kostiscodefresh-io\/"}]}},"acf":[],"_links":{"self":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts\/13905"}],"collection":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/users\/62"}],"replies":[{"embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/comments?post=13905"}],"version-history":[{"count":1,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts\/13905\/revisions"}],"predecessor-version":[{"id":20941,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts\/13905\/revisions\/20941"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/media\/13819"}],"wp:attachment":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/media?parent=13905"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/categories?post=13905"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/tags?post=13905"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}