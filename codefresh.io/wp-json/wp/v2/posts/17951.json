{"id":17951,"date":"2020-11-12T03:14:24","date_gmt":"2020-11-12T11:14:24","guid":{"rendered":"https:\/\/codefresh.io\/?p=17951"},"modified":"2022-03-01T17:18:42","modified_gmt":"2022-03-01T17:18:42","slug":"docker-memory-usage","status":"publish","type":"post","link":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/","title":{"rendered":"My Process Used Minimal Memory, and My Docker Memory Usage Exploded"},"content":{"rendered":"<p>The Docker infrastructure abstracts a lot of aspects of the creation of images and running them as containers, which we usually do not know about nor interact with. One of those aspects is the handling of the filesystem inside the container.<\/p>\n<p>This post is a case study on how we discovered that writing large amounts of data inside a container has side effects with memory caching. Initially, we thought that we had an issue with our source code, but this was never the case.<\/p>\n<p>In this post, we will see:<\/p>\n<ul>\n<li>A walkthrough on how you can reproduce the memory issue that we encountered<\/li>\n<li>How we discovered a temporary workaround<\/li>\n<li>The steps we followed to find a proper solution<\/li>\n<\/ul>\n<p>If you want to know more about the way Docker abstraction behaves and you always had unexplained questions about large memory usage, then this post is for you.<\/p>\n<h2>How Docker Handles Memory Allocation<\/h2>\n<p>Before we dive into our specific scenario, we want to give an overview of how memory allocation and usage works in Docker.<\/p>\n<p>Docker does not apply memory limitations to containers by default. The Host\u2019s Kernel Scheduler determines the capacity provided to the Docker memory. This means that in theory, it is possible for a Docker container to consume the entire host\u2019s memory.<\/p>\n<p>One way to control the memory used by Docker is by setting the runtime configuration flags of the \u2019docker run command\u2019. There are specific scenarios when you will want to set these limitations.<\/p>\n<p>Generally, you want to prevent the container from consuming too much of the host machine\u2019s memory. In the case of Linux, once the Kernel detects that it will run out of memory, it will throw an \u2019Out Of Memory Exception\u2019 and will kill processes to free up memory.<\/p>\n<p>Usually, those processes are ordered by priority, which is determined by the OOM (Out of Memory) killer. However, if the wrong process is killed, the entire system might crash.<\/p>\n<p>Contrary to popular belief, even if you set a memory limit to your container, it does not automatically mean that the container will only consume the allocated memory. You can try this out yourself. The following example allocates 60mb of memory inside of a container with 50mb. You would expect the OOME to kill the process. However, it does not. To try it out, run:<\/p>\n<pre>docker run --memory 50m --rm -it progrium\/stress --vm 1 --vm-bytes 62914560 --timeout 1s\r\n<\/pre>\n<p>To prevent this from happening, you have to define the memory-swap in addition to the memory by setting it equal to the memory:<\/p>\n<pre>docker run --memory 50m --memory-swap 50m --rm -it progrium\/stress --vm 1 --vm-bytes 62914560 --timeout 1s\r\n<\/pre>\n<p>Note that this will only work if your Docker has <a href=\"https:\/\/docs.docker.com\/install\/linux\/linux-postinstall\/\">cgroup memory and swap accounting<\/a> enabled.<\/p>\n<p>The official Docker documentation provides more details on the steps that you can take to restrict the container\u2019s memory usage; here are the main points:<\/p>\n<ul>\n<li>Perform tests to understand the memory requirements of your application before placing it into production.<\/li>\n<li>Ensure that your application runs only on hosts with adequate resources.<\/li>\n<li>Limit the amount of memory your container can use, as described in the official Docker documentation.<\/li>\n<li>Be mindful when configuring swap on your Docker hosts. Swap is slower and less performant than memory but can provide a buffer against running out of system memory.<\/li>\n<li>Consider converting your container to a<a href=\"https:\/\/docs.docker.com\/engine\/swarm\/services\/\"> service<\/a>, and using service-level constraints and node labels to ensure that the application runs only on hosts with enough memory.<\/li>\n<\/ul>\n<p>More information can be found in the <a href=\"https:\/\/docs.docker.com\/config\/containers\/resource_constraints\/\">official Docker documentation for runtime options<\/a>.<\/p>\n<h2>Observing a memory issue with our ETL script<\/h2>\n<p>This section provides an overview of our script and details how you can recreate the memory bloat using Codefresh and the YAML file provided.<\/p>\n<p>The issue appeared when we ran an\u00a0 ETL (extract-transform-load) application inside a container.<\/p>\n<p>The details of the business purpose behind the application are not that important. In short, this is the process that our application was supposed to follow:<\/p>\n<ol>\n<li>Pull quite a lot of open-source data into memory<\/li>\n<li>Convert the data and write it into a single file on the filesystem<\/li>\n<li>Next, upload the file to Google Cloud and populate it into BigQuery<\/li>\n<\/ol>\n<p>The resulting file consists of about 20 million lines, so we expected the process to take some time.<\/p>\n<p>However, we observed that after a while, we received a memory indication warning. The container then slowed down and finally crashed.<\/p>\n<h2>Reproducing the issue with Node.js<\/h2>\n<p>Just to confirm that our application code is not at fault here we reproduce the error with a simple script running in Node.js, image node:12.13.0 :<\/p>\n<pre class=\"\">'use strict';\r\nconst fs = require('fs');\r\nconst sameFile =process.env.SAME_FILE;\r\n\r\n\/\/node --max-old-space-size=400 .\/checkBloat.js\r\nconst main = async () =&gt; {\r\n    let totalWrite = 0;\r\n    let fileCnt = 0;\r\n    let numFiles = 1;\r\n\r\n    while(true) {\r\n        const filename = sameFile ? ' file' : `file${numFiles}`;\r\n        const theFile = fs.openSync(filename, 'w');\r\n        for(let i=1; i&lt;10000000+1;i++){ fileCnt=i; fs.writeSync(theFile, `${i}) =================================================================&gt;${Math.random()}`);\r\n            totalWrite+=1;\r\n            if (totalWrite%100000===0) {\r\n                console.log(`${filename} ${numFiles}) cnt: ${fileCnt})total written: ${totalWrite} `);\r\n            }\r\n        }\r\n        console.log(`CLOSE FILE } `);\r\n        fs.closeSync(theFile);\r\n        numFiles++;\r\n    };\r\n};\r\n\r\nPromise.resolve()\r\n    .then( async () =&gt; {\r\n            await main();\r\n    });\r\n<\/pre>\n<p>This script reproduces the effect of the memory climbing up close to the limit of the underlying machine and staying there. This could continue until the device filesystem is full. Then, we would try to log into a Unix shell and flush the memory, in which case it would crash.<\/p>\n<h2>Reproducing the issue with a Python script<\/h2>\n<p>To compare with our Node.js script, we ran the same logic in Python. This would verify the fact that the application code is not a fault, but instead something is wrong with the container runtime.<\/p>\n<p>We rewrote the NodeJs script in Python. The Python script would seem to work in the beginning but at some point, there was no more room to write the data to the output file and we would receive the following error message: OSError: [Errno 28] No space left on device<\/p>\n<pre class=\"\">import os\r\nimport sys\r\nfrom collections import defaultdict\r\nlines = 0\r\nfile_cnt = 0\r\n\r\nd=defaultdict(list)\r\nfor k, v in ((k.lstrip('-'), v) for k,v in (a.split('=') for a in sys.argv[1:])):\r\n     d[k].append(v)\r\nprint (d)\r\nlimit = int(d.get('limit')[0]) if  d.get('limit')  else None\r\nsame_file =  False if not d.get('bloat') or d.get('bloat')[0] in ['true', 'on'] else True\r\nstats =  True if not d.get('stats') or d.get('stats')[0] in ['true', 'on'] else False\r\nprint (f'argv = {sys.argv} limit: {limit} same_file {same_file}  stats {stats}')\r\n# create the file encoded for the yaml\r\nos.system('FNAME=\"write_lots.py\" &amp;&amp; cat \"$FNAME\" | python -m base64 &gt; \"$FNAME.b64\"')\r\nwhile(limit is None or lines&lt; limit) : file_cnt += 1 filename= f'file' if same_file else f'bloat{file_cnt}' f = open(f'{filename}', \"w\") for x in range(1,1000*1000+1): f.write(f'{file_cnt}) {x}: write line {lines} ============================================&gt; \\n');\r\n     lines += 1\r\n     if (lines%(1000*1000)==0):\r\n        print(f'Written {file_cnt} {filename}) {x}: write line {lines}')\r\n  f.close()\r\n  print(f'{file_cnt}) close {filename} written {x} total {lines} ');\r\n  if (stats):\r\n     try:\r\n        os.system('''ps auxww | grep -E \"python [w]rite_lots|[P]ID \" ''')\r\n        os.system('free')\r\n     except(e):\r\n        pass\r\n<\/pre>\n<p>The python code has options to use the same file\/stats and sizes as our original source code.<\/p>\n<h2>Reproducing in the Codefresh Platform<\/h2>\n<p>Instead of running the script separately, you can also use the following codefresh.yml file with the python code embedded. Note that the long string is the embedded Python code.<\/p>\n<pre class=\"\">version: \"1.0\"\r\nstages:  []\r\nsteps:\r\n  run:\r\n    title: \"Running process\"\r\n    image: python\r\n    commands:\r\n            - ls\r\n            - pwd\r\n            - FNAME=\"write_lots.py\"\r\n            - echo ' content was created by bash&gt; FNAME=\"write_lots.py\" &amp;&amp; cat \"$FNAME\" | python -m base64 &gt; \"$FNAME.b64\" '\r\n            - &gt;-\r\n                echo  \"\r\n                       aW1wb3J0IG9zCmltcG9ydCBzeXMKZnJvbSBjb2xsZWN0aW9ucyBpbXBvcnQgZGVmYXVsdGRpY3QK\r\n                       bGluZXMgPSAwCmZpbGVfY250ID0gMApkPWRlZmF1bHRkaWN0KGxpc3QpCmZvciBrLCB2IGluICgo\r\n                       ay5sc3RyaXAoJy0nKSwgdikgZm9yIGssdiBpbiAoYS5zcGxpdCgnPScpIGZvciBhIGluIHN5cy5h\r\n                       cmd2WzE6XSkpOgogICAgICBkW2tdLmFwcGVuZCh2KQpwcmludCAoZCkKbGltaXQgPSBpbnQoZC5n\r\n                       ZXQoJ2xpbWl0JylbMF0pIGlmICBkLmdldCgnbGltaXQnKSAgZWxzZSBOb25lCnNhbWVfZmlsZSA9\r\n                       ICBGYWxzZSBpZiBub3QgZC5nZXQoJ2Jsb2F0Jykgb3IgZC5nZXQoJ2Jsb2F0JylbMF0gaW4gWyd0\r\n                       cnVlJywgJ29uJ10gZWxzZSBUcnVlCnN0YXRzID0gIFRydWUgaWYgbm90IGQuZ2V0KCdzdGF0cycp\r\n                       IG9yIGQuZ2V0KCdzdGF0cycpWzBdIGluIFsndHJ1ZScsICdvbiddIGVsc2UgRmFsc2UKZmlsZXNp\r\n                       emUgPSAgaW50KGZsb2F0KGQuZ2V0KCdmaWxlc2l6ZScpWzBdKSoxMDAwMDAwMCkgaWYgZC5nZXQo\r\n                       J2ZpbGVzaXplJykgZWxzZSAgMTAwMDAwMDAKcHJpbnQgKGYnYXJndiA9IHtzeXMuYXJndn0gbGlt\r\n                       aXQ6IHtsaW1pdH0gc2FtZV9maWxlIHtzYW1lX2ZpbGV9ICBzdGF0cyB7c3RhdHN9IGZpbGVzaXpl\r\n                       IHtmaWxlc2l6ZX0nKSAKIyBjcmVhdGUgdGhlIGZpbGUgZW5jb2RlZCBmb3IgdGhlIHlhbWwKb3Mu\r\n                       c3lzdGVtKCdGTkFNRT0id3JpdGVfbG90cy5weSIgJiYgY2F0ICIkRk5BTUUiIHwgcHl0aG9uIC1t\r\n                       IGJhc2U2NCA+ICIkRk5BTUUuYjY0IicpCndoaWxlKGxpbWl0IGlzIE5vbmUgb3IgbGluZXM8IGxp\r\n                       bWl0KSA6CiAgIGZpbGVfY250ICs9IDEKICAgZmlsZW5hbWU9ICBmJ2ZpbGUnIGlmIHNhbWVfZmls\r\n                       ZSBlbHNlIGYnYmxvYXR7ZmlsZV9jbnR9JyAKICAgZiA9IG9wZW4oZid7ZmlsZW5hbWV9JywgInci\r\n                       KQogICBmb3IgeCBpbiByYW5nZSgxLGZpbGVzaXplKzEpOgogICAgICBmLndyaXRlKGYne2ZpbGVf\r\n                       Y250fSkge3h9OiB3cml0ZSBsaW5lIHtsaW5lc30gPT09PT09PT09PT09PT09PT09PT09PT09PT09\r\n                       PT09PT09PT09PT09PT09PT0+IFxuJyk7CiAgICAgIGxpbmVzICs9IDEKICAgICAgaWYgKGxpbmVz\r\n                       JSgxMDAqMTAwMCk9PTApOgogICAgICAgICBwcmludChmJ1dyaXR0ZW4ge2ZpbGVfY250fSB7Zmls\r\n                       ZW5hbWV9KSB7eH06IHdyaXRlIGxpbmUge2xpbmVzfScpCiAgIGYuY2xvc2UoKQogICBwcmludChm\r\n                       J3tmaWxlX2NudH0pIGNsb3NlIHtmaWxlbmFtZX0gd3JpdHRlbiB7eH0gdG90YWwge2xpbmVzfSAn\r\n                       KTsKICAgaWYgKHN0YXRzKToKICAgICAgdHJ5OgogICAgICAgICBvcy5zeXN0ZW0oJycncHMgYXV4\r\n                       d3cgfCBncmVwIC1FICJweXRob24gW3ddcml0ZV9sb3RzfFtQXUlEICIgJycnKQogICAgICAgICBv\r\n                       cy5zeXN0ZW0oJ2ZyZWUnKQogICAgICBleGNlcHQoZSk6CiAgICAgICAgIHBhc3MKCgoK\r\n                \" &gt; \"$FNAME.b64\"\r\n            - ls\r\n            - cat \"$FNAME.b64\" | python -m base64 -d &gt; \"$FNAME\"\r\n            - ls -ltr\r\n            - echo \"the code\"\r\n            - cat \"$FNAME\"\r\n            - date\r\n            - echo \"no bloat\"\r\n            - python \"$FNAME\" limit=400000000 bloat=off stats=on filesize=1\r\n            - date\r\n            - echo \"would bloat\"\r\n            - python \"$FNAME\" limit=400000000 bloat=on stats=on filesize=1\r\n            - echo done\r\n            - date\r\n\r\n<\/pre>\n<p><b>To use this in your Codefresh pipeline, follow these steps.<\/b><\/p>\n<ul>\n<li>First set-up your <a href=\"https:\/\/codefresh.io\/docs\/docs\/getting-started\/create-a-codefresh-account\/\">Codefresh account.<\/a>\n<p><figure id=\"attachment_17811\" aria-describedby=\"caption-attachment-17811\" style=\"width: 300px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard.png\"><img class=\"size-medium wp-image-17811\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard-300x170.png\" alt=\"project-dashboard\" width=\"300\" height=\"170\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard-300x170.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard-1024x580.png 1024w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard-768x435.png 768w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard-20x11.png 20w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/10\/project-dashboard.png 1226w\" sizes=\"(max-width: 300px) 100vw, 300px\" \/><\/a><figcaption id=\"caption-attachment-17811\" class=\"wp-caption-text\">Create a new pipeline<\/figcaption><\/figure><\/li>\n<li>Next, create a project and set-up a pipeline within the project.<\/li>\n<li>When you create the pipeline, make sure to turn the \u201cadd git example\u201d off.\n<p><figure id=\"attachment_17956\" aria-describedby=\"caption-attachment-17956\" style=\"width: 300px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/create-new-project.png\"><img class=\"size-medium wp-image-17956\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/create-new-project-300x181.png\" alt=\"create-new-pipeline\" width=\"300\" height=\"181\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/create-new-project-300x181.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/create-new-project-20x12.png 20w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/create-new-project.png 733w\" sizes=\"(max-width: 300px) 100vw, 300px\" \/><\/a><figcaption id=\"caption-attachment-17956\" class=\"wp-caption-text\">Create a new pipeline<\/figcaption><\/figure><\/li>\n<li>It will provide a template codefresh.yml file by default. Replace this file with the YAML file above. This will show some warnings but should not throw any errors.\n<figure id=\"attachment_17957\" aria-describedby=\"caption-attachment-17957\" style=\"width: 300px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/paste-the-yaml.png\"><img class=\"size-medium wp-image-17957\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/paste-the-yaml-300x272.png\" alt=\"paste-the-yaml\" width=\"300\" height=\"272\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/paste-the-yaml-300x272.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/paste-the-yaml-768x696.png 768w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/paste-the-yaml-20x18.png 20w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/paste-the-yaml.png 996w\" sizes=\"(max-width: 300px) 100vw, 300px\" \/><\/a><figcaption id=\"caption-attachment-17957\" class=\"wp-caption-text\">Paste the yaml into your pipeline<\/figcaption><\/figure>\n<ul>\n<li>Next, run the pipeline.<\/li>\n<li>You can view the output in the Codefresh Console.<\/li>\n<\/ul>\n<\/li>\n<\/ul>\n<p>The pipeline runs the code twice. We have added a command-line option to our script (called <b>bloat<\/b>) which decides if we use a single file for output (our original design) or multiple files but with the same name (we will explain the choice in the next section).<\/p>\n<p>The pipeline will still crash with an out of memory error.<\/p>\n<figure id=\"attachment_17959\" aria-describedby=\"caption-attachment-17959\" style=\"width: 300px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline.png\"><img class=\"size-medium wp-image-17959\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline-300x153.png\" alt=\"crashed-pipeline\" width=\"300\" height=\"153\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline-300x153.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline-1024x522.png 1024w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline-768x392.png 768w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline-1536x783.png 1536w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline-20x10.png 20w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/crashed-pipeline.png 1600w\" sizes=\"(max-width: 300px) 100vw, 300px\" \/><\/a><figcaption id=\"caption-attachment-17959\" class=\"wp-caption-text\">Crashed Pipeline<\/figcaption><\/figure>\n<h2>Kubernetes analysis<\/h2>\n<p>Even though the problem seems to be Docker related, our initial analysis was started with Kubernetes (Codefresh is running pipeline inside Docker containers on a Kubernetes cluster).<\/p>\n<p>To debug the issue we ran the following command in order to get a shell inside the container.<\/p>\n<pre># NS=the namespace  NAME= the container name\r\nkubectl -n $NS exec --stdin --tty $NAME -- \/bin\/bash  \r\n<\/pre>\n<p>We looked at the buffer\/cache by running the <a href=\"https:\/\/linuxize.com\/post\/free-command-in-linux\/\">Linux free<\/a> command. This showed growing memory usage:<\/p>\n<figure id=\"attachment_17960\" aria-describedby=\"caption-attachment-17960\" style=\"width: 300px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/memory-usage.png\"><img class=\"size-medium wp-image-17960\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/memory-usage-300x111.png\" alt=\"memory-usage\" width=\"300\" height=\"111\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/memory-usage-300x111.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/memory-usage-20x7.png 20w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/memory-usage.png 717w\" sizes=\"(max-width: 300px) 100vw, 300px\" \/><\/a><figcaption id=\"caption-attachment-17960\" class=\"wp-caption-text\">Memory usage using the free command<\/figcaption><\/figure>\n<p>Next, we tried removing all the code and focused on the process of creating the file to see whether it is a problem with the code or the file generation and usage. In this case, the same thing happened and the memory still increased.<\/p>\n<p>We cross-checked whether it was the code or creating the file by writing into \/dev\/null. Dev\/null is a file that is present in every Linux OS, also known as the null device on UNIX systems, and sometimes called \u2018the black hole\u2019. It is only used to write, and whatever is written into dev\/null will be immediately disregarded.<\/p>\n<figure id=\"attachment_17961\" aria-describedby=\"caption-attachment-17961\" style=\"width: 255px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/dev-null-example.png\"><img class=\"size-full wp-image-17961\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/dev-null-example.png\" alt=\"dev-null-example\" width=\"255\" height=\"59\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/dev-null-example.png 255w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/dev-null-example-20x5.png 20w\" sizes=\"(max-width: 255px) 100vw, 255px\" \/><\/a><figcaption id=\"caption-attachment-17961\" class=\"wp-caption-text\">Example using dev null<\/figcaption><\/figure>\n<p>So the assumption is that writing into this file should not have any effect on the memory used.<\/p>\n<p>However, using \/dev\/null did not change anything. The memory also bloated in this case. We now knew the issue is related to writing the file.<\/p>\n<h2>First approach: clearing the memory cache<\/h2>\n<p>Now that we know what the issue was, we had to find a solution or workaround.<\/p>\n<p>The next step that most developers would take is searching online for answers (i.e. the stack overflow approach). Thus, we looked for combined issues with the buff\/cached and the free command.<\/p>\n<p>This gave us the following search results:<\/p>\n<ul>\n<li>&#8220;buff\/cache &#8211; The combined memory used by the kernel buffers and page cache and slabs. This memory can be reclaimed at any time if needed by the applications.&#8221;<\/li>\n<\/ul>\n<p>These commands force\/trigger to clear the cache, which should usually clear automatically when the need arises. To try this out, either of the following commands would work:<\/p>\n<ul>\n<li>one way: echo 1 &gt; \/proc\/sys\/vm\/drop_caches<\/li>\n<li>Another, less hacky: sysctl -w vm.drop_caches=1<\/li>\n<\/ul>\n<p>The screenshot below shows the size of the cache before and after.<\/p>\n<figure id=\"attachment_17962\" aria-describedby=\"caption-attachment-17962\" style=\"width: 300px\" class=\"wp-caption aligncenter\"><a href=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/size-cache-difference.png\"><img class=\"size-medium wp-image-17962\" src=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/size-cache-difference-300x101.png\" alt=\"size-cache-difference\" width=\"300\" height=\"101\" srcset=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/size-cache-difference-300x101.png 300w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/size-cache-difference-20x7.png 20w, https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/size-cache-difference.png 647w\" sizes=\"(max-width: 300px) 100vw, 300px\" \/><\/a><figcaption id=\"caption-attachment-17962\" class=\"wp-caption-text\">Size Cache Difference<\/figcaption><\/figure>\n<p>Next, we used a one-liner script in the shell to keep the process alive and the cache low:<\/p>\n<ul>\n<li>while sleep 60; do sysctl -w vm.drop_caches=1 ; echo .; done<\/li>\n<\/ul>\n<p>When we were calling the script in the shell on the running container, the process did finish like expected. However, while running the script in combination with our own process, it still failed. In this case, we used the following command:<\/p>\n<pre>sysctl -w vm.drop_caches=1\r\n=&gt; sysctl: setting key \"vm.drop_caches\": Read-only file system\r\n<\/pre>\n<p>Note that our Kubernetes cluster used spot instances. Thus, there might be other reasons for the crash than memory bloat. The best practice, especially when using spot instances, is to build the process as incremental work. If the process fails, restarting it will not make it work the second time around. In this case, the work would have to be down-scaled again.<\/p>\n<p>If you are interested in the topic, you can find several suggestions online related to increasing proc\/sys\/vm\/<a href=\"https:\/\/docs.gluster.org\/en\/latest\/Administrator%20Guide\/Linux%20Kernel%20Tuning\/#vmvfs_cache_pressure\">vfs_cache_pressure<\/a>.<\/p>\n<h2>Second approach: Using Multiple Files instead of one<\/h2>\n<p>Remember how we mentioned above that the file we wanted to transfer had over 20 million lines of data? Our second thought was that something along executing the file could have messed with our process, or that the file was simply too large. A colleague suggested writing many files instead of executing a single big one. Thus we divided the content across multiple files. At first, we used the following naming pattern: job1.json, job2.json&#8230;<\/p>\n<p>It turned out, using multiple files was a lot better in various ways. Each file would run in sequential order. This allowed us to see the progress of the job and play with partial data.<\/p>\n<p>But unfortunately, the process still failed in the end and we were back to square one.<\/p>\n<p>Third approach: Using a single file multiple times<\/p>\n<p>Our last approach was simply using the same filename &#8220;job&#8221; for each batch of work instead of naming every file differently.<\/p>\n<p>In this case, the kernel clears the cached filesystem buffer nodes when the file is deleted\/truncated.<\/p>\n<p>Finally, this solved the issue and our ETL application finished successfully! Hurray!<\/p>\n<p>One way to avoid writing large amounts of data to the file system is to write the data to a different destination like an external bucket service which is not cached by the Linux file system.<\/p>\n<h2>Final Thoughts<\/h2>\n<p>When we started the experiments, we expected to see deterministic behavior. We expected the process to run as defined in the source code and produce the same output every time.<\/p>\n<p>What we saw instead was a different behavior every time we ran the script.<\/p>\n<p>Running our script always produced a different result depending on cluster type, memory allocation, and timing. This made our process quite unpredictable and added difficulty in determining the issues. Every time we would change one of the variables before running the code, the outcome would be different. It could result in a crash, the memory limit was reached, a slow down of our CPU, or we would receive an OSError: [Errno 28] No space left on device.<\/p>\n<p>Overall, there is a lot more going on behind the Docker infrastructure abstraction which our script does not reveal.<\/p>\n<p>While we did not find a definite cause of the problem, we found a workaround. Here are the main takeaways:<\/p>\n<ul>\n<li>When using Docker, don\u2019t write large amounts of data into your filesystem. Instead, write it directly into external services.<\/li>\n<li>If you still have to store data at an intermediate location, use a limited memory space and overwrite\/delete the data once it is no longer needed. By flushing the buffer\/cache we can avoid a memory bloat.<\/li>\n<li>Do not reuse the same file to record an extensive amount of data.<\/li>\n<li>Lastly, you should understand the implications of using spot instances for your Kubernetes cluster.<\/li>\n<\/ul>\n<p>Please let us know in the comments whether this story was interesting to you and whether you would like to read more of this type. Also, please share with us any questions or suggestions for us and for the community.<\/p>\n<p>If you are new to Codefresh <a href=\"https:\/\/codefresh.io\/codefresh-signup\/?utm_source=Blog&amp;utm_medium=Post&amp;utm_campaign=dockermemoryexplosion\">Create Your Free Account today<\/a> and try out the memory bloat!<\/p>\n<input class=\"fooboxshare_post_id\" type=\"hidden\" value=\"17951\"\/>","protected":false},"excerpt":{"rendered":"<p>The Docker infrastructure abstracts a lot of aspects of the creation of images and running them as containers, which we usually do not know about nor interact with. One of those aspects is the handling of the filesystem inside the container. This post is a case study on how we discovered that writing large amounts &hellip; <a href=\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/\">Read more<\/a><\/p>\n","protected":false},"author":83,"featured_media":20539,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[8,1543,1538,6],"tags":[14,961,3504,5510,5515,5542,5543,5544,5545],"yoast_head":"<!-- This site is optimized with the Yoast SEO Premium plugin v17.9 (Yoast SEO v18.4.1) - https:\/\/yoast.com\/wordpress\/plugins\/seo\/ -->\n<title>My Process Used Minimal Memory, and My Docker Memory Usage Exploded | Codefresh<\/title>\n<meta name=\"robots\" content=\"index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1\" \/>\n<link rel=\"canonical\" href=\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/\" \/>\n<meta property=\"og:locale\" content=\"en_US\" \/>\n<meta property=\"og:type\" content=\"article\" \/>\n<meta property=\"og:title\" content=\"My Process Used Minimal Memory, and My Docker Memory Usage Exploded\" \/>\n<meta property=\"og:description\" content=\"The Docker infrastructure abstracts a lot of aspects of the creation of images and running them as containers, which we usually do not know about nor interact with. One of those aspects is the handling of the filesystem inside the container. This post is a case study on how we discovered that writing large amounts &hellip; Read more\" \/>\n<meta property=\"og:url\" content=\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/\" \/>\n<meta property=\"og:site_name\" content=\"Codefresh\" \/>\n<meta property=\"article:publisher\" content=\"https:\/\/www.facebook.com\/codefresh.io\" \/>\n<meta property=\"article:published_time\" content=\"2020-11-12T11:14:24+00:00\" \/>\n<meta property=\"article:modified_time\" content=\"2022-03-01T17:18:42+00:00\" \/>\n<meta property=\"og:image\" content=\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg\" \/>\n\t<meta property=\"og:image:width\" content=\"2560\" \/>\n\t<meta property=\"og:image:height\" content=\"1706\" \/>\n\t<meta property=\"og:image:type\" content=\"image\/jpeg\" \/>\n<meta name=\"twitter:card\" content=\"summary_large_image\" \/>\n<meta name=\"twitter:creator\" content=\"@codefresh\" \/>\n<meta name=\"twitter:site\" content=\"@codefresh\" \/>\n<meta name=\"twitter:label1\" content=\"Written by\" \/>\n\t<meta name=\"twitter:data1\" content=\"Saffi Hartal\" \/>\n\t<meta name=\"twitter:label2\" content=\"Est. reading time\" \/>\n\t<meta name=\"twitter:data2\" content=\"13 minutes\" \/>\n<script type=\"application\/ld+json\" class=\"yoast-schema-graph\">{\"@context\":\"https:\/\/schema.org\",\"@graph\":[{\"@type\":\"Organization\",\"@id\":\"https:\/\/codefresh.io\/#organization\",\"name\":\"Codefresh\",\"url\":\"https:\/\/codefresh.io\/\",\"sameAs\":[\"https:\/\/www.facebook.com\/codefresh.io\",\"https:\/\/www.linkedin.com\/company\/codefresh\",\"https:\/\/www.youtube.com\/channel\/UC9r94SY6BqN05kXPIHsDXPg\",\"https:\/\/twitter.com\/codefresh\"],\"logo\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/codefresh.io\/#logo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png\",\"contentUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png\",\"width\":800,\"height\":800,\"caption\":\"Codefresh\"},\"image\":{\"@id\":\"https:\/\/codefresh.io\/#logo\"}},{\"@type\":\"WebSite\",\"@id\":\"https:\/\/codefresh.io\/#website\",\"url\":\"https:\/\/codefresh.io\/\",\"name\":\"Codefresh\",\"description\":\"\",\"publisher\":{\"@id\":\"https:\/\/codefresh.io\/#organization\"},\"potentialAction\":[{\"@type\":\"SearchAction\",\"target\":{\"@type\":\"EntryPoint\",\"urlTemplate\":\"https:\/\/codefresh.io\/?s={search_term_string}\"},\"query-input\":\"required name=search_term_string\"}],\"inLanguage\":\"en-US\"},{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#primaryimage\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg\",\"contentUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg\",\"width\":2560,\"height\":1706},{\"@type\":\"WebPage\",\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#webpage\",\"url\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/\",\"name\":\"My Process Used Minimal Memory, and My Docker Memory Usage Exploded | Codefresh\",\"isPartOf\":{\"@id\":\"https:\/\/codefresh.io\/#website\"},\"primaryImageOfPage\":{\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#primaryimage\"},\"datePublished\":\"2020-11-12T11:14:24+00:00\",\"dateModified\":\"2022-03-01T17:18:42+00:00\",\"breadcrumb\":{\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#breadcrumb\"},\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"ReadAction\",\"target\":[\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/\"]}]},{\"@type\":\"BreadcrumbList\",\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#breadcrumb\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Home\",\"item\":\"https:\/\/codefresh.io\/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"My Process Used Minimal Memory, and My Docker Memory Usage Exploded\"}]},{\"@type\":\"Article\",\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#article\",\"isPartOf\":{\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#webpage\"},\"author\":{\"@id\":\"https:\/\/codefresh.io\/#\/schema\/person\/8a1663dec0a5f7f7f216545cc4b8d341\"},\"headline\":\"My Process Used Minimal Memory, and My Docker Memory Usage Exploded\",\"datePublished\":\"2020-11-12T11:14:24+00:00\",\"dateModified\":\"2022-03-01T17:18:42+00:00\",\"mainEntityOfPage\":{\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#webpage\"},\"wordCount\":2208,\"commentCount\":2,\"publisher\":{\"@id\":\"https:\/\/codefresh.io\/#organization\"},\"image\":{\"@id\":\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#primaryimage\"},\"thumbnailUrl\":\"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg\",\"keywords\":[\"docker\",\"pipeline\",\"linux\",\"codefresh pipeline\",\"tutorial\",\"Docker memory\",\"linux command\",\"memory bloat\",\"memory usage\"],\"articleSection\":[\"Docker Tutorials\",\"Continuous Integration\",\"DevOps Tutorials\",\"How Tos\"],\"inLanguage\":\"en-US\",\"potentialAction\":[{\"@type\":\"CommentAction\",\"name\":\"Comment\",\"target\":[\"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#respond\"]}]},{\"@type\":\"Person\",\"@id\":\"https:\/\/codefresh.io\/#\/schema\/person\/8a1663dec0a5f7f7f216545cc4b8d341\",\"name\":\"Saffi Hartal\",\"image\":{\"@type\":\"ImageObject\",\"@id\":\"https:\/\/codefresh.io\/#personlogo\",\"inLanguage\":\"en-US\",\"url\":\"https:\/\/secure.gravatar.com\/avatar\/98d4482cb6ce6d25f64e2ebfdc0d29fb?s=96&d=blank&r=g\",\"contentUrl\":\"https:\/\/secure.gravatar.com\/avatar\/98d4482cb6ce6d25f64e2ebfdc0d29fb?s=96&d=blank&r=g\",\"caption\":\"Saffi Hartal\"},\"description\":\"Backend Developer at Codefresh\",\"url\":\"https:\/\/codefresh.io\/author\/saffihartal\/\"}]}<\/script>\n<!-- \/ Yoast SEO Premium plugin. -->","yoast_head_json":{"title":"My Process Used Minimal Memory, and My Docker Memory Usage Exploded | Codefresh","robots":{"index":"index","follow":"follow","max-snippet":"max-snippet:-1","max-image-preview":"max-image-preview:large","max-video-preview":"max-video-preview:-1"},"canonical":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/","og_locale":"en_US","og_type":"article","og_title":"My Process Used Minimal Memory, and My Docker Memory Usage Exploded","og_description":"The Docker infrastructure abstracts a lot of aspects of the creation of images and running them as containers, which we usually do not know about nor interact with. One of those aspects is the handling of the filesystem inside the container. This post is a case study on how we discovered that writing large amounts &hellip; Read more","og_url":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/","og_site_name":"Codefresh","article_publisher":"https:\/\/www.facebook.com\/codefresh.io","article_published_time":"2020-11-12T11:14:24+00:00","article_modified_time":"2022-03-01T17:18:42+00:00","og_image":[{"width":2560,"height":1706,"url":"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg","type":"image\/jpeg"}],"twitter_card":"summary_large_image","twitter_creator":"@codefresh","twitter_site":"@codefresh","twitter_misc":{"Written by":"Saffi Hartal","Est. reading time":"13 minutes"},"schema":{"@context":"https:\/\/schema.org","@graph":[{"@type":"Organization","@id":"https:\/\/codefresh.io\/#organization","name":"Codefresh","url":"https:\/\/codefresh.io\/","sameAs":["https:\/\/www.facebook.com\/codefresh.io","https:\/\/www.linkedin.com\/company\/codefresh","https:\/\/www.youtube.com\/channel\/UC9r94SY6BqN05kXPIHsDXPg","https:\/\/twitter.com\/codefresh"],"logo":{"@type":"ImageObject","@id":"https:\/\/codefresh.io\/#logo","inLanguage":"en-US","url":"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png","contentUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2022\/02\/Codefresh_Logo_Vertical_LightBkgd.png","width":800,"height":800,"caption":"Codefresh"},"image":{"@id":"https:\/\/codefresh.io\/#logo"}},{"@type":"WebSite","@id":"https:\/\/codefresh.io\/#website","url":"https:\/\/codefresh.io\/","name":"Codefresh","description":"","publisher":{"@id":"https:\/\/codefresh.io\/#organization"},"potentialAction":[{"@type":"SearchAction","target":{"@type":"EntryPoint","urlTemplate":"https:\/\/codefresh.io\/?s={search_term_string}"},"query-input":"required name=search_term_string"}],"inLanguage":"en-US"},{"@type":"ImageObject","@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#primaryimage","inLanguage":"en-US","url":"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg","contentUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg","width":2560,"height":1706},{"@type":"WebPage","@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#webpage","url":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/","name":"My Process Used Minimal Memory, and My Docker Memory Usage Exploded | Codefresh","isPartOf":{"@id":"https:\/\/codefresh.io\/#website"},"primaryImageOfPage":{"@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#primaryimage"},"datePublished":"2020-11-12T11:14:24+00:00","dateModified":"2022-03-01T17:18:42+00:00","breadcrumb":{"@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#breadcrumb"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/"]}]},{"@type":"BreadcrumbList","@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#breadcrumb","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/codefresh.io\/"},{"@type":"ListItem","position":2,"name":"My Process Used Minimal Memory, and My Docker Memory Usage Exploded"}]},{"@type":"Article","@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#article","isPartOf":{"@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#webpage"},"author":{"@id":"https:\/\/codefresh.io\/#\/schema\/person\/8a1663dec0a5f7f7f216545cc4b8d341"},"headline":"My Process Used Minimal Memory, and My Docker Memory Usage Exploded","datePublished":"2020-11-12T11:14:24+00:00","dateModified":"2022-03-01T17:18:42+00:00","mainEntityOfPage":{"@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#webpage"},"wordCount":2208,"commentCount":2,"publisher":{"@id":"https:\/\/codefresh.io\/#organization"},"image":{"@id":"https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#primaryimage"},"thumbnailUrl":"https:\/\/codefresh.io\/wp-content\/uploads\/2020\/11\/cargo-ship-docker-ian-taylor-jOqJbvo1P9g-unsplash-scaled.jpg","keywords":["docker","pipeline","linux","codefresh pipeline","tutorial","Docker memory","linux command","memory bloat","memory usage"],"articleSection":["Docker Tutorials","Continuous Integration","DevOps Tutorials","How Tos"],"inLanguage":"en-US","potentialAction":[{"@type":"CommentAction","name":"Comment","target":["https:\/\/codefresh.io\/docker-tutorial\/docker-memory-usage\/#respond"]}]},{"@type":"Person","@id":"https:\/\/codefresh.io\/#\/schema\/person\/8a1663dec0a5f7f7f216545cc4b8d341","name":"Saffi Hartal","image":{"@type":"ImageObject","@id":"https:\/\/codefresh.io\/#personlogo","inLanguage":"en-US","url":"https:\/\/secure.gravatar.com\/avatar\/98d4482cb6ce6d25f64e2ebfdc0d29fb?s=96&d=blank&r=g","contentUrl":"https:\/\/secure.gravatar.com\/avatar\/98d4482cb6ce6d25f64e2ebfdc0d29fb?s=96&d=blank&r=g","caption":"Saffi Hartal"},"description":"Backend Developer at Codefresh","url":"https:\/\/codefresh.io\/author\/saffihartal\/"}]}},"acf":[],"_links":{"self":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts\/17951"}],"collection":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/users\/83"}],"replies":[{"embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/comments?post=17951"}],"version-history":[{"count":3,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts\/17951\/revisions"}],"predecessor-version":[{"id":21741,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/posts\/17951\/revisions\/21741"}],"wp:featuredmedia":[{"embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/media\/20539"}],"wp:attachment":[{"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/media?parent=17951"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/categories?post=17951"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/codefresh.io\/wp-json\/wp\/v2\/tags?post=17951"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}